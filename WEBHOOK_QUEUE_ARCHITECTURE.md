# ğŸ—ï¸ Webhook Queue Architecture - Learning Guide

## ğŸ“š Table of Contents
1. [Why We Need Queues](#why-we-need-queues)
2. [How AWS SQS Works](#how-aws-sqs-works)
3. [Architecture Flow](#architecture-flow)
4. [Code Implementation](#code-implementation)
5. [Concurrency & Race Conditions](#concurrency--race-conditions)

---

## ğŸ¯ Why We Need Queues

### Current Problem: Synchronous Processing

When ROOK sends 10-11 webhooks instantly:

```
Webhook 1: Sleep Data    â”€â”
Webhook 2: Activity Data â”€â”¤
Webhook 3: Body Data     â”€â”¤â”€â†’ All hit MongoDB at same time
Webhook 4: Heart Rate    â”€â”¤
...                      â”€â”˜
```

**What happens:**
1. All webhooks call `User.findById(userId)` simultaneously
2. Each gets a COPY of the user document
3. Each modifies its copy independently
4. Each calls `.save()` - **LAST ONE WINS, others lost!** ğŸ’¥

### Solution: Queue-Based Processing

```
Webhook 1 â”€â”
Webhook 2 â”€â”¤
Webhook 3 â”€â”¤â”€â†’ SQS Queue â”€â†’ Worker processes ONE at a time
Webhook 4 â”€â”¤              â”€â†’ No race conditions!
...       â”€â”˜
```

---

## ğŸŒŠ How AWS SQS Works

### SQS = Simple Queue Service (Message Buffer)

Think of SQS like a **line at Starbucks**:
- Customers (webhooks) arrive in bursts
- They join a queue (SQS)
- Barista (worker) serves ONE customer at a time
- No one gets their order mixed up!

### Key Concepts:

#### 1. **Producer** (Your webhook endpoint)
```typescript
// Fast operation: Just add message to queue
await sqs.send(new SendMessageCommand({
  QueueUrl: "https://sqs.us-east-1.amazonaws.com/xxx/rook-health-webhooks",
  MessageBody: JSON.stringify(webhookData)
}));
// Returns immediately! No waiting for processing.
```

#### 2. **Queue** (AWS SQS)
```
Messages waiting: [msg1, msg2, msg3, msg4, ...]
                   â†‘
                   Worker polls here
```

Properties:
- **Visibility Timeout**: 60s (worker has 60s to process before message becomes visible again)
- **Message Retention**: 4 days (if worker fails, message stays for retry)
- **Dead Letter Queue**: After 3 failed attempts, move to DLQ for manual investigation

#### 3. **Consumer** (Worker process)
```typescript
// Continuously polls SQS
while (true) {
  const messages = await sqs.receiveMessage({ MaxMessages: 1 });
  
  for (const message of messages) {
    await processWebhook(message); // Do the heavy work
    await sqs.deleteMessage(message); // Remove from queue
  }
}
```

---

## ğŸ”„ Architecture Flow

### Step-by-Step Webhook Processing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. ROOK sends webhook                                       â”‚
â”‚    POST /api/webhooks/rook/health-data                      â”‚
â”‚    Body: { user_id, data_structure, physical_health: {...} }â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Webhook Controller (FAST - <50ms)                        â”‚
â”‚    âœ“ Verify HMAC signature                                  â”‚
â”‚    âœ“ Store raw payload in MongoDB (rook_raw_webhooks)       â”‚
â”‚    âœ“ Send to SQS queue                                      â”‚
â”‚    âœ“ Return 200 OK to ROOK immediately                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. AWS SQS Queue (Buffer)                                   â”‚
â”‚    Message stored safely, waiting for worker                â”‚
â”‚    Retry if worker fails (automatic!)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Worker Process (SLOW - runs separately)                  â”‚
â”‚    Poll SQS every 1 second                                  â”‚
â”‚    Get ONE message at a time                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Process Message                                          â”‚
â”‚    â€¢ Find user by external_user_id (MongoDB ObjectId)       â”‚
â”‚    â€¢ Transform webhook data (extract sleep/activity/body)   â”‚
â”‚    â€¢ Atomic MongoDB update (no race conditions!)            â”‚
â”‚    â€¢ Clear Redis cache                                      â”‚
â”‚    â€¢ Delete message from SQS                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© Code Implementation

### 1. Raw Webhook Storage (Immutable Audit Log)

**Why?** Keep original webhook for:
- Debugging (if processing fails, replay it)
- Compliance (audit trail)
- Data recovery (if transformation had a bug)

```typescript
// models/RawWebhook.model.ts
{
  provider: "rook",
  externalUserId: "68da80c9ffda7e51bd9ac167",
  dataStructure: "sleep_summary",
  payload: { /* entire ROOK payload */ },
  receivedAt: ISODate("2025-12-23T10:00:00Z"),
  processed: false,
  processedAt: null,
  error: null
}
```

### 2. SQS Message Format

```json
{
  "provider": "rook",
  "data_structure": "sleep_summary",
  "external_user_id": "68da80c9ffda7e51bd9ac167",
  "raw_webhook_id": "67890abc...",
  "payload": {
    "version": 2,
    "sleep_health": { /* ROOK data */ }
  },
  "receivedAt": "2025-12-23T10:00:00.000Z"
}
```

### 3. Worker Processing Logic

```typescript
// Pseudo-code
async function processMessage(message) {
  const { external_user_id, payload, data_structure, raw_webhook_id } = message;
  
  // 1. Find user
  const user = await User.findById(external_user_id);
  if (!user) {
    // Mark as failed but DON'T delete raw webhook
    await RawWebhook.findByIdAndUpdate(raw_webhook_id, {
      processed: true,
      error: "User not found"
    });
    return;
  }
  
  // 2. Transform data
  const transformed = HealthDataTransformer.transform(payload);
  // transformed = { sleep: {...}, activity: {...}, body: {...} }
  
  // 3. Get data type
  const dataType = getDataType(data_structure);
  // "sleep_summary" â†’ "sleep"
  
  // 4. ATOMIC UPDATE (no race conditions!)
  await User.findByIdAndUpdate(external_user_id, {
    $set: {
      [`wearables.garmin.data.${dataType}`]: transformed[dataType],
      [`wearables.garmin.lastSync`]: new Date(),
      [`wearables.garmin.connected`]: true
    }
  });
  
  // 5. Clear cache
  await redis.del(`wearables:${external_user_id}`);
  
  // 6. Mark as processed
  await RawWebhook.findByIdAndUpdate(raw_webhook_id, {
    processed: true,
    processedAt: new Date()
  });
}
```

---

## âš¡ Concurrency & Race Conditions

### Understanding the Problem

**Bad Code (Race Condition):**
```typescript
// âŒ DON'T DO THIS
const user = await User.findById(userId);  // Read
user.wearables.garmin.data.sleep = newData; // Modify
await user.save();                          // Write

// If 2 webhooks run this simultaneously:
// Webhook 1: Read (gets v1) â†’ Modify sleep â†’ Write (saves v2)
// Webhook 2: Read (gets v1) â†’ Modify activity â†’ Write (saves v3, OVERWRITES sleep!)
```

**Good Code (Atomic Update):**
```typescript
// âœ… DO THIS
await User.findByIdAndUpdate(userId, {
  $set: {
    "wearables.garmin.data.sleep": newData
  }
});

// MongoDB guarantees this happens atomically (all-or-nothing)
// Even if 10 webhooks call this, no data loss!
```

### How MongoDB Handles Atomic Updates

```
MongoDB receives 3 update commands simultaneously:
  Update 1: Set sleep data     â”€â”
  Update 2: Set activity data  â”€â”¤â”€â†’ MongoDB queues them internally
  Update 3: Set body data      â”€â”˜   Executes ONE at a time

Result: All 3 updates applied correctly, no overwrites!
```

---

## ğŸ“ Key Takeaways

1. **Webhooks should respond FAST** (<100ms) - Just store and enqueue
2. **Heavy processing happens async** - Worker polls SQS
3. **Always use atomic updates** - No find â†’ modify â†’ save
4. **Keep raw webhooks** - Immutable audit log for replay
5. **SQS handles retries** - No manual retry loops needed

---

## ğŸ“Š Performance Benefits

**Before (Synchronous):**
```
Webhook processing time: 500-1000ms per webhook
10 webhooks = 5-10 seconds total
ROOK may timeout and retry!
```

**After (Queue-Based):**
```
Webhook response time: <50ms (just store + enqueue)
10 webhooks = <500ms total (all queued instantly!)
Worker processes them in background (5-10 seconds)
No ROOK timeouts!
```

---

## ğŸš€ Next Steps

1. Set up AWS SQS queue
2. Implement SQS producer in webhook controller
3. Create worker process
4. Test with ROOK JSON simulator
5. Deploy worker to EC2
6. Monitor CloudWatch metrics

Let's build it! ğŸ› ï¸
