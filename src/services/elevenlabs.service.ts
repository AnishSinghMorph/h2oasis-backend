import fetch from "node-fetch";
import FormData from "form-data";

// ElevenLabs Configuration
const ELEVENLABS_CONFIG = {
  API_KEY: process.env.ELEVENLABS_API_KEY,
  BASE_URL: "https://api.elevenlabs.io/v1",
};

export class ElevenLabsAPI {
  /**
   * Convert speech to text using ElevenLabs STT API
   */
  static async speechToText(
    audioBuffer: Buffer,
    mimeType: string,
  ): Promise<string> {
    try {
      if (!ELEVENLABS_CONFIG.API_KEY) {
        throw new Error("ElevenLabs API key not configured");
      }

      console.log("üé§ Sending audio to ElevenLabs STT API...");
      console.log("üìÑ Audio info:", { size: audioBuffer.length, mimeType });

      // Create form data for the audio file
      const formData = new FormData();

      // Determine file extension from mime type
      const extension =
        mimeType.includes("mp4") || mimeType.includes("m4a")
          ? "m4a"
          : mimeType.includes("webm")
            ? "webm"
            : mimeType.includes("wav")
              ? "wav"
              : "mp3";

      formData.append("file", audioBuffer, {
        filename: `audio.${extension}`,
        contentType: mimeType,
      });

      // Add required model_id parameter (required by ElevenLabs STT API)
      formData.append("model_id", "scribe_v1");

      // Force English language detection
      formData.append("language", "en");

      // ElevenLabs STT API endpoint
      const response = await fetch(
        `${ELEVENLABS_CONFIG.BASE_URL}/speech-to-text`,
        {
          method: "POST",
          headers: {
            "xi-api-key": ELEVENLABS_CONFIG.API_KEY,
            ...formData.getHeaders(),
          },
          body: formData,
        },
      );

      console.log("üì° STT Response status:", response.status);

      if (!response.ok) {
        const errorText = await response.text();
        console.error("ElevenLabs STT Error Response:", errorText);
        throw new Error(
          `ElevenLabs STT API error: ${response.status} ${response.statusText} - ${errorText}`,
        );
      }

      const result = (await response.json()) as any;
      console.log("‚úÖ STT Response:", result);

      // ElevenLabs returns the transcription in different possible fields
      const transcription =
        result.text || result.transcription || result.transcript || "";

      if (!transcription) {
        throw new Error("No transcription received from ElevenLabs STT API");
      }

      return transcription.trim();
    } catch (error: any) {
      console.error("‚ùå ElevenLabs STT Error:", error);

      // Provide more helpful error messages
      if (error?.message?.includes("ECONNRESET")) {
        throw new Error(
          "Network connection error. Please check your internet connection and try again.",
        );
      } else if (error?.message?.includes("timeout")) {
        throw new Error(
          "Request timeout. Please try with a shorter audio recording.",
        );
      } else if (error?.message?.includes("401")) {
        throw new Error(
          "Invalid ElevenLabs API key. Please check your configuration.",
        );
      } else if (error?.message?.includes("413")) {
        throw new Error(
          "Audio file too large. Please try with a shorter recording.",
        );
      } else {
        throw error;
      }
    }
  }

  /**
   * Get available voices from ElevenLabs
   */
  static async getVoices(): Promise<any[]> {
    try {
      if (!ELEVENLABS_CONFIG.API_KEY) {
        throw new Error("ElevenLabs API key not configured");
      }

      const response = await fetch(`${ELEVENLABS_CONFIG.BASE_URL}/voices`, {
        headers: {
          "xi-api-key": ELEVENLABS_CONFIG.API_KEY,
        },
      });

      if (!response.ok) {
        throw new Error(
          `ElevenLabs API error: ${response.status} ${response.statusText}`,
        );
      }

      const result = (await response.json()) as any;
      return result.voices || [];
    } catch (error) {
      console.error("‚ùå ElevenLabs Voices Error:", error);
      throw error;
    }
  }
}
